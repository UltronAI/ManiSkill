{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaofeng/miniconda3/envs/arm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from mani_skill.envs.sapien_env import BaseEnv\n",
    "from mani_skill.utils.wrappers import RecordEpisode\n",
    "from mani_skill.utils.structs.pose import Pose\n",
    "from mani_skill.utils.geometry import rotation_conversions as rot_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "env_id = \"TestBench-v1\"\n",
    "\n",
    "num_envs = 1\n",
    "seed = 10\n",
    "quiet = False\n",
    "render_mode = \"human\"\n",
    "parallel_in_single_scene = False\n",
    "obs_mode = \"none\"\n",
    "reward_mode = None\n",
    "control_mode = \"pd_joint_pos\" #\"pd_ee_target_delta_pose\"\n",
    "shader_dir = \"default\"\n",
    "sim_backend = \"auto\"\n",
    "\n",
    "pause = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MESA-INTEL: warning: Performance support disabled, consider sysctl dev.i915.perf_stream_paranoid=0\n",
      "\n",
      "MESA-INTEL: warning: Performance support disabled, consider sysctl dev.i915.perf_stream_paranoid=0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done adding gripper constraint\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=3)\n",
    "verbose = True\n",
    "\n",
    "env: BaseEnv = gym.make(\n",
    "        env_id,\n",
    "        obs_mode=obs_mode,\n",
    "        reward_mode=reward_mode,\n",
    "        control_mode=control_mode,\n",
    "        render_mode=render_mode,\n",
    "        shader_dir=shader_dir,\n",
    "        num_envs=num_envs,\n",
    "        sim_backend=sim_backend,\n",
    "        parallel_in_single_scene=parallel_in_single_scene,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Observation space\", env.observation_space)\n",
    "print(\"Action space\", env.action_space)\n",
    "print(\"Control mode\", env.unwrapped.control_mode)\n",
    "print(\"Reward mode\", env.unwrapped.reward_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, _ = env.reset(seed=seed)\n",
    "env.action_space.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: <class 'torch.Tensor'> torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaofeng/miniconda3/envs/arm/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent` for environment variables or `env.get_wrapper_attr('agent')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "from mani_skill.utils import common\n",
    "import torch\n",
    "\n",
    "# tt = common.to_tensor(torch.tensor([[0.5, 0.5]])[0, 0])\n",
    "env.agent.controller.controllers['gripper'].set_drive_targets(\n",
    "                                                              torch.tensor([[0.5, 0.5]]))\n",
    "# action = env.action_space.sample()\n",
    "# print(action.shape)\n",
    "\n",
    "# aa = env.agent.controller.controllers['gripper']._preprocess_action(action)\n",
    "# print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if render_mode is not None:\n",
    "    viewer = env.render()\n",
    "    viewer.paused = pause\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.agent.controller.controllers['arm'].ee_pose)\n",
    "print(env.agent.controller.controllers['arm'].ee_pose_at_base)\n",
    "print(env.agent.controller.controllers['arm']._target_pose)\n",
    "\n",
    "\n",
    "start_pose = env.agent.controller.controllers['arm'].ee_pose_at_base\n",
    "BASE_pose = env.agent.robot.get_links()[0].pose\n",
    "\n",
    "print(BASE_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_pose(pose1, pose2, alpha: float):\n",
    "    \"\"\"\n",
    "    Interpolates between two Pose objects given an interpolation factor alpha (0 <= alpha <= 1).\n",
    "    \n",
    "    :param pose1: The starting Pose object.\n",
    "    :param pose2: The ending Pose object.\n",
    "    :param alpha: Interpolation factor (0 = pose1, 1 = pose2).\n",
    "    :return: A new Pose object that is the interpolated result.\n",
    "    \"\"\"\n",
    "    # Linearly interpolate positions\n",
    "    interp_position = (1 - alpha) * pose1.p + alpha * pose2.p\n",
    "    \n",
    "    # Perform SLERP for quaternion interpolation\n",
    "    dot_product = torch.sum(pose1.q * pose2.q, dim=-1, keepdim=True)\n",
    "    if torch.all(dot_product < 0):\n",
    "        pose2.q = -pose2.q\n",
    "        dot_product = -dot_product\n",
    "\n",
    "    dot_product = torch.clamp(dot_product, -1.0, 1.0)\n",
    "\n",
    "    theta_0 = torch.acos(dot_product)\n",
    "    sin_theta_0 = torch.sin(theta_0)\n",
    "\n",
    "    if torch.all(sin_theta_0 > 1e-6):\n",
    "        sin_theta = torch.sin(alpha * theta_0)\n",
    "        sin_theta_1 = torch.sin((1 - alpha) * theta_0)\n",
    "        interp_quat = (sin_theta_1 / sin_theta_0) * pose1.q + (sin_theta / sin_theta_0) * pose2.q\n",
    "    else:\n",
    "        interp_quat = pose1.q\n",
    "\n",
    "    # Normalize the resulting quaternion to avoid numerical drift\n",
    "    interp_quat = torch.nn.functional.normalize(interp_quat)\n",
    "\n",
    "    # Create and return the new interpolated Pose\n",
    "    return Pose.create_from_pq(interp_position, interp_quat)\n",
    "\n",
    "\n",
    "def generate_trajectory(poses, durations, control_frequency):\n",
    "    \"\"\"\n",
    "    Generates a smooth trajectory to control the end-effector.\n",
    "    \n",
    "    :param poses: List of poses, where each pose is [x, y, z, qw, qx, qy, qz]\n",
    "    :param durations: List of durations between consecutive poses\n",
    "    :param control_frequency: Scalar frequency to determine the number of internal poses per second\n",
    "    :return: List of interpolated poses (smooth trajectory)\n",
    "    \"\"\"\n",
    "    trajectory = []\n",
    "    num_segments = len(poses) - 1\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_pose = poses[i]\n",
    "        end_pose = poses[i + 1]\n",
    "        duration = durations[i]\n",
    "        \n",
    "        num_steps = int(duration * control_frequency)\n",
    "        for step in range(num_steps):\n",
    "            alpha = step / num_steps\n",
    "            interp_pose = interpolate_pose(start_pose, end_pose, alpha)\n",
    "            trajectory.append(interp_pose)\n",
    "    \n",
    "    # Add the last pose to ensure the trajectory ends exactly at the final pose\n",
    "    trajectory.append(poses[-1])\n",
    "    \n",
    "    return trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "p = torch.tensor([0.3, -0.3, 0.0])\n",
    "q = rot_utils.axis_angle_to_quaternion(torch.tensor([0, 0, torch.pi/2]))\n",
    "target_pose = Pose.create_from_pq(p, q)\n",
    "print(target_pose.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = generate_trajectory([start_pose, target_pose], [2], env.agent.controller.control_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start:\", start_pose.p, start_pose.q)\n",
    "for ttt in traj:\n",
    "    print(ttt.p, ttt.q)\n",
    "print(\"end:\", target_pose.p, target_pose.q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta_pose(pose1: Pose, pose2: Pose) -> (torch.Tensor, torch.Tensor):\n",
    "    \"\"\"\n",
    "    Computes the delta position and delta rotation (in Euler angles) between two poses.\n",
    "    \n",
    "    :param pose1: The initial Pose object.\n",
    "    :param pose2: The final Pose object.\n",
    "    :return: A tuple containing delta position (torch.Tensor) and delta rotation (in Euler angles, torch.Tensor).\n",
    "    \"\"\"\n",
    "    # Delta Position\n",
    "    delta_position = pose2.p - pose1.p\n",
    "    \n",
    "    # Compute relative rotation (delta rotation)\n",
    "    quat1 = pose1.q\n",
    "    quat2 = pose2.q\n",
    "    \n",
    "    # Calculate the relative quaternion (pose1 to pose2)\n",
    "    relative_quat = quaternion_multiply(quat2, quaternion_conjugate(quat1))\n",
    "    \n",
    "    # Convert the relative quaternion to Euler angles\n",
    "    relative_rotation = rot_utils.quaternion_to_axis_angle(relative_quat)\n",
    "    delta_rotation = torch.tensor(relative_rotation, device=pose1.device)\n",
    "    \n",
    "    return delta_position, delta_rotation\n",
    "\n",
    "def quaternion_conjugate(quat):\n",
    "    \"\"\"\n",
    "    Computes the conjugate of a quaternion.\n",
    "    \n",
    "    :param quat: The quaternion tensor [w, x, y, z].\n",
    "    :return: The conjugated quaternion tensor.\n",
    "    \"\"\"\n",
    "    conjugate = quat.clone()\n",
    "    conjugate[..., 1:] *= -1  # Negate the vector part\n",
    "    return conjugate\n",
    "\n",
    "def quaternion_multiply(quat1, quat2):\n",
    "    \"\"\"\n",
    "    Multiplies two quaternions.\n",
    "    \n",
    "    :param quat1: First quaternion tensor [w, x, y, z].\n",
    "    :param quat2: Second quaternion tensor [w, x, y, z].\n",
    "    :return: Resulting quaternion after multiplication.\n",
    "    \"\"\"\n",
    "    w1, x1, y1, z1 = quat1[..., 0], quat1[..., 1], quat1[..., 2], quat1[..., 3]\n",
    "    w2, x2, y2, z2 = quat2[..., 0], quat2[..., 1], quat2[..., 2], quat2[..., 3]\n",
    "    \n",
    "    w = w1*w2 - x1*x2 - y1*y2 - z1*z2\n",
    "    x = w1*x2 + x1*w2 + y1*z2 - z1*y2\n",
    "    y = w1*y2 + y1*w2 + z1*x2 - x1*z2\n",
    "    z = w1*z2 + z1*w2 + x1*y2 - y1*x2\n",
    "    \n",
    "    return torch.stack((w, x, y, z), dim=-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "for i in range(len(traj)-1):\n",
    "    delta_pose = compute_delta_pose(traj[i], traj[i+1])\n",
    "    print(delta_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(traj)-1):\n",
    "    delta_pose = compute_delta_pose(traj[i], traj[i+1])\n",
    "    action = torch.cat([delta_pose[0], delta_pose[1]], dim=1)\n",
    "    \n",
    "    _ = env.step(action)\n",
    "    \n",
    "    print(\"Expect pose:\", traj[i+1].p, traj[i+1].q)\n",
    "    print(\"Actual pose:\", env.agent.controller.controllers['arm'].ee_pose_at_base.p, env.agent.controller.controllers['arm'].ee_pose_at_base.q)\n",
    "    \n",
    "    env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
